{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ecb8a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.compat.v1.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cac6e1",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebbcd23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = tfds.load(\"imdb_reviews\",as_supervised= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a62b1e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
       " 'test': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
       " 'unsupervised': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e63e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set= imdb[\"train\"]\n",
    "test_set = imdb[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d6df3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence = []\n",
    "train_label = []\n",
    "test_sentence = []\n",
    "test_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9d56551",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, label in test_set:\n",
    "    test_sentence.append(str(sentence.numpy()))\n",
    "    test_label.append(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef16dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, label in train_set:\n",
    "    train_sentence.append(str(sentence.numpy()))\n",
    "    train_label.append(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d7745c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000 25000 25000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentence), len(train_label), len(test_sentence), len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "238c634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> <class 'list'> <class 'str'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_sentence[0]), type(train_label), type(test_sentence[0]), type(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8ed59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_label)\n",
    "test_labels = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1fdc0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_label), type(test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c44af3b",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "900e9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "drop_embed = 0.2 \n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "num_epoch =5\n",
    "trunc_type = \"post\"\n",
    "oov_tok = \"<OOV>\"\n",
    "n_lstm = 256\n",
    "drop_lstm = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca980572",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "299fb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "625ef105",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0dc4e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_sequences_sentence = tokenizer.texts_to_sequences(train_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53f06b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_sequences_sentence = tokenizer.texts_to_sequences(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eabdc3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 12, 14, 35, 439, 400, 18, 174, 29, 1, 9, 33, 1, 1, 42, 496, 1, 197, 25, 88, 156, 19, 12, 211, 340, 29, 70, 248, 213, 9, 486, 62, 70, 88, 116, 99, 24, 1, 12, 1, 657, 777, 12, 18, 7, 35, 406, 1, 178, 1, 426, 2, 92, 1, 140, 72, 149, 55, 2, 1, 1, 72, 229, 70, 1, 16, 1, 1, 1, 1, 1, 1, 3, 40, 1, 119, 1, 17, 1, 14, 163, 19, 4, 1, 927, 1, 9, 4, 18, 13, 14, 1, 5, 102, 148, 1, 11, 240, 692, 13, 44, 25, 101, 39, 12, 1, 1, 39, 1, 1, 52, 409, 11, 99, 1, 874, 145, 10]\n"
     ]
    }
   ],
   "source": [
    "print(train_to_sequences_sentence[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d9150",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bdca70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = pad_sequences(train_to_sequences_sentence, maxlen= max_length, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b45734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded = pad_sequences(test_to_sequences_sentence,maxlen= max_length, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9d3f980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 120) (25000, 120)\n"
     ]
    }
   ],
   "source": [
    "print(train_padded.shape, test_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdafca77",
   "metadata": {},
   "source": [
    "# Developing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3ce7f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size,output_dim=embedding_dim, input_length=max_length),\n",
    "    SpatialDropout1D(drop_embed),\n",
    "    Bidirectional(LSTM(units=n_lstm, dropout=drop_lstm)),\n",
    "    Flatten(),\n",
    "    Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59a9506b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 120, 16)           16000     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 120, 16)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 512)               559104    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 575,617\n",
      "Trainable params: 575,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b8ce3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\",\n",
    "             optimizer = \"adam\",\n",
    "             metrics = [\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1a061a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 277s 11ms/sample - loss: 0.6795 - accuracy: 0.5772 - val_loss: 0.6913 - val_accuracy: 0.5042\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 258s 10ms/sample - loss: 0.6609 - accuracy: 0.5989 - val_loss: 0.5421 - val_accuracy: 0.7362\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 205s 8ms/sample - loss: 0.5173 - accuracy: 0.7458 - val_loss: 0.5979 - val_accuracy: 0.6409\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 201s 8ms/sample - loss: 0.4744 - accuracy: 0.7796 - val_loss: 0.4260 - val_accuracy: 0.8042\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 183s 7ms/sample - loss: 0.4299 - accuracy: 0.8070 - val_loss: 0.4166 - val_accuracy: 0.8073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7005b8690>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_padded,train_labels,\n",
    "         epochs = num_epoch,\n",
    "         validation_data = (test_padded, test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf9e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "caf5fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = [\"This movie is the worst thing ever I watched\",\n",
    "           \"I hate the actor in this movie\",\n",
    "              \"This movie is fucking awful\",\n",
    "              \"This movie is the most terrible movie i have watched with horrible actor\",\n",
    "           \"Do not watch this movie because this movie is really bad\",\n",
    "           \"Fuck this movie. It is really bad\",\n",
    "           \"This movie is the best\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b0fd8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1_text_to_sequence = tokenizer.texts_to_sequences(sentence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3e19cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1_sequence_padded = pad_sequences(sentence_1_text_to_sequence,maxlen = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fcf860ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1393053 ],\n",
       "       [0.42358458],\n",
       "       [0.12012677],\n",
       "       [0.06273458],\n",
       "       [0.25805876],\n",
       "       [0.31871018],\n",
       "       [0.64907765]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_probabilities= model.predict_proba(sentence_1_sequence_padded)\n",
    "output_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "952df0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This movie is the worst thing ever I watched \n",
      " ['0.14%']\n",
      "\n",
      "\n",
      "I hate the actor in this movie \n",
      " ['0.42%']\n",
      "\n",
      "\n",
      "This movie is fucking awful \n",
      " ['0.12%']\n",
      "\n",
      "\n",
      "This movie is the most terrible movie i have watched with horrible actor \n",
      " ['0.06%']\n",
      "\n",
      "\n",
      "Do not watch this movie because this movie is really bad \n",
      " ['0.26%']\n",
      "\n",
      "\n",
      "Fuck this movie. It is really bad \n",
      " ['0.32%']\n",
      "\n",
      "\n",
      "This movie is the best \n",
      " ['0.65%']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(output_probabilities)):\n",
    "    print(\"\\n\")\n",
    "    print(sentence_1[i], \"\\n\", list(map('{:.2f}%'.format,output_probabilities[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b81cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
